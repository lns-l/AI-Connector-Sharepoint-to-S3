# IntegraÃ§Ã£o SharePoint âœ S3 com Docker Compose

Este projeto executa dois processos automatizados em containers distintos, com comunicaÃ§Ã£o via volume compartilhado:

1. **`generate_json_master.py`** â€” extrai metadados de arquivos do SharePoint e os salva localmente em `.json`.
2. **`sharepoint_pdf_to_s3_json.py`** â€” lÃª os `.json`, baixa PDFs, converte para texto e envia para o S3.

---

## ğŸ“ Estrutura de DiretÃ³rios

```
.
â”œâ”€â”€ compose.yaml                # Docker Compose com dois containers
â”œâ”€â”€ Dockerfile                  # Imagem base comum aos dois serviÃ§os
â”œâ”€â”€ .env                        # VariÃ¡veis de ambiente e agendamento
â”œâ”€â”€ requirements.txt            # DependÃªncias Python
â”œâ”€â”€ generate_json_master.py     # Script 1
â”œâ”€â”€ sharepoint_pdf_to_s3_json.py# Script 2
â”œâ”€â”€ export_sharepoint/          # Pasta onde JSONs sÃ£o gerados
â””â”€â”€ temp_pdfs/                  # Pasta temporÃ¡ria para PDFs e JSONs convertidos
```

---

## âš™ï¸ VariÃ¡veis de Ambiente (.env)

Exemplo:

```env
# Intervalos de execuÃ§Ã£o (em segundos)
STEP1_INTERVAL=600         # a cada 10 minutos
STEP2_INTERVAL=900         # a cada 15 minutos

# SharePoint
TENANT_ID=seu-tenant-id
CLIENT_ID=seu-client-id
CLIENT_SECRET=sua-chave
SHAREPOINT_SITE=seusite.sharepoint.com
SITE_PATH=/sites/seusite
DRIVE_NAME=Documents

# AWS S3
AWS_ACCESS_KEY=sua-chave-aws
AWS_SECRET_KEY=sua-chave-secreta-aws
S3_BUCKET=seu-bucket
S3_PREFIX=sharepoint-export/

# Pastas compartilhadas
GENERATE_PATH=./export_sharepoint
LOCAL_TEMP_DIR=./temp_pdfs
```

---

## ğŸš€ Como Executar

1. **Clone ou extraia os arquivos em uma pasta local:**

2. **Configure o arquivo `.env` com seus dados de autenticaÃ§Ã£o.**

3. **Execute os containers com:**

```bash
docker compose -f compose.yaml up --build -d
```

4. **Acompanhe os logs (opcional):**

```bash
docker logs -f generate_json
docker logs -f upload_s3
```

---

## ğŸ” Funcionamento AutomÃ¡tico

- O container `generate_json` executa o primeiro script conforme o `STEP1_INTERVAL`.
- O container `upload_s3` verifica se hÃ¡ JSONs em `export_sharepoint/`. Se houver, executa o segundo script, e aguarda conforme `STEP2_INTERVAL`.

---

## âœ… Requisitos

- Docker e Docker Compose instalados
- Acesso Ã  API do Microsoft Graph
- Bucket e credenciais vÃ¡lidas da AWS S3

---

## â“ DÃºvidas ou melhorias?

Sinta-se Ã  vontade para adaptar os tempos, caminhos, ou integrar logs com ferramentas como Grafana, CloudWatch ou ELK Stack.

---

Desenvolvido para facilitar o fluxo automÃ¡tico de dados entre SharePoint e S3 via JSON e PDF.
